---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

# <i class="fa fa-fw fa-copy"></i> Publications #

<!-- ## Conference Articles ## -->
<p>
<img src="https://ming1993li.github.io/images/StyleTailor.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback</b><br>Hongbo Ma, Fei Shen, Hongbin Xu, Xiaoce Wang, Gang Xu, Jinkai Zheng, Liangqiong Qu and <b>Ming Li</b>*. <i>Under Review</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/pdf/2508.06555">Paper</a>][<a href="https://mahb-thu.github.io/StyleTailor.github.io/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/unif2ace2.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>UniF^2ace: A Unified Fine-grained Face Understanding and Generation Model</b><br>Junzhe Li, Sifan Zhou, Liya Guo, Xuerui Qiu, Linrui Xu, Delin Qu, Tingting Long, Chun Fan, <b>Ming Li</b>*, Hehe Fan, Jun Liu, and Shuicheng Yan. <i>Under Review</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/pdf/2503.08120">Paper</a>][<a href="https://huggingface.co/papers/2503.08120">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/CyC3D.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>CyC3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization</b><br>Hongbin Xu, Chaohui Yu, Feng Xiao, Jiazheng Xing, Hai Ci, Weitao Chen and <b>Ming Li</b>*. <i>Under Review</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2504.14975">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/favchat.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>FaVChat: Unlocking Fine-Grained Facail Video Understanding with Multimodal Large Language Models</b><br>Fufangchen Zhao, <b>Ming Li</b>*†, Linrui Xu, Wenhao Jiang, Jian Gao and Danfeng Yan. <i>Under Review</i>. 2025. (*Corresponding Authors, †Equal Contributors)<br>[<a href="http://arxiv.org/pdf/2503.09158">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/safe-var.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>Safe-VAR: Safe Visual Autoregressive Model for Text-to-Image Generative Watermarking</b><br>Ziyi Wang, Songbai Tan, Gang Xu, Xuerui Qiu, Hongbin Xu, Xin Meng, <b>Ming Li</b>* and Fei Richard Yu. <i>Under Review</i>. 2025. (*Corresponding Authors)<br>[<a href="https://arxiv.org/pdf/2503.11324">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/CustStyle.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on 3D Gaussians</b><br>Cailin Zhuang, Yaoqi Hu, Xuanyang Zhang, Wei Cheng, Jiacheng Bao, Shengqi Liu, Yiying Yang, Xianfang Zeng, Gang Yu and <b>Ming Li</b>*. <i>Under Review</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2504.15281">Paper</a>][<a href="https://styleme3d.github.io/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/XSGS.png?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>X-SGS: Safe and Generalizable Gaussian Splatting with X-dimensional Watermarks</b><br>Zihang Cheng, Huiping Zhuang, Chun Li, Xin Meng, <b>Ming Li</b>*, Fei Richard Yu, Liqiang Nie. <i>Under Review</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2502.10475">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/SafeSora.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking</b><br>Zihan Su, Xuerui Qiu, Hongbin Xu, Tangyu Jiang, Junhao Zhuang, Chun Yuan, <b>Ming Li</b>*, Shengfeng He, and Fei Richard Yu. <i>NeurIPS</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/pdf/2505.12667">Paper</a>][<a href="https://sugewud.github.io/Safe-Sora-project/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/pvchat.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>PVChat: Personalized Video Chat with One-Shot Learning</b><br>Yufei Shi†, Weilong Yan†, Gang Xu, Yumeng Li, Yucheng Chen,
Zhenxi Li, Fei Richard Yu, Ming Li* and Si Yong Yeo. <i>ICCV</i>. 2025. (*Corresponding Authors, †Equal Contributors)<br>[<a href="https://arxiv.org/pdf/2503.17069">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/WMarkGPT.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>WMarkGPT: Watermarked Image Understanding via Multimodal Large Language Models</b><br>Songbai Tan, Yao Shu, Xuerui Qiu, Gang Xu, Linrui Xu, Xiangyu Xu, Huiping Zhuang, <b>Ming Li</b>* and Fei Richard Yu. <i>ICML</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://openreview.net/pdf?id=HjVhSL76GM">Paper</a>][<a href="https://github.com/TanSongBai/WMarkGPT?tab=readme-ov-file">Project</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/FedVLA.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation</b><br>Cui Miao, Tao Chang, Meihan Wu, Hongbin Xu, Chun Li, <b>Ming Li</b>*, Xiaodong Wang. <i>ICCV</i>. 2025. (*Corresponding Authors)<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/EFTViT.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>EFTViT: Efficient Federated Training of Vision Transformers with Masked Images on Resource-Constrained Edge Devices</b><br>Meihan Wu, Tao Chang, Miaocui, Jie Zhou, Chun Li, Xiangyu Xu, <b>Ming Li</b>*, and Xiaodong Wang. <i>ICCV</i>. 2025. (*Corresponding Authors)<br> 
[<a href="http://arxiv.org/abs/2412.00334">Paper</a>][<a href="http://arxiv.org/abs/2412.00334">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/EventGPT.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>EventGPT: Event Stream Understanding with Multimodal Large Language Models</b><br>Shaoyu liu, Jianing Li, Guanghui Zhao, Yunjian Zhang, Xin Meng, Fei Richard Yu, Xiangyang Ji, and <b>Ming Li</b>*. <i>CVPR</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2412.00832">Paper</a>][<a href="https://xdusyl.github.io/eventgpt.github.io/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/Inter3D.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object Reconstruction</b><br>Gan Chen, Ying He, Mulin Yu, F.Richard Yu, Gang Xu, Fei Ma, <b>Ming Li</b>* and Guang Zhou. <i>IJCAI</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/pdf/2502.14004">Paper</a>][<a href="https://github.com/Inter3D-ui/Inter3D">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/TextSplat.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting</b><br>Zhicong Wu, Hongbin Xu, Gang Xu, Ping Nie, Zhixin Yan, Jinkai Zheng, Liangqiong Qu, <b>Ming Li</b>* and Liqiang Nie. <i>ACM MM</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2504.09588">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/depth.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/><b>Synthetic-to-Real Self-supervised Robust Depth Estimation via Learning with Motion and Structure Priors</b><br>Weilong Yan, <b>Ming Li</b>, Haipeng Li, Shuwei Shao, Robby T. Tan. <i>CVPR</i>. 2025.<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/Zhipeng.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures</b><br>Zhipeng Xue†, Yan Zhang†, <b>Ming Li</b>†, Chun Li, Yue Liu, and Fei Richard Yu. <i>IEEE TIP</i>. 2025. (†Equal Contributors)<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/Zhangyan.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Uncertainty Quantification via Holder Divergence for Multi-View Representation Learning</b><br>Yan Zhang†, <b>Ming Li</b>†, Chun Li, Zhaoxia Liu, Ye Zhang, and Fei Richard Yu. <i>IEEE TMM</i>. 2025. (†Equal Contributors)<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/Brain.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using H¨older Divergence and Mutual Information-Enhanced Knowledge Transfer</b><br>Runze Cheng†, Xihang Qiu†, <b>Ming Li</b>†, Ye Zhang, Fei Richard Yu, and Chun Li. <i>IEEE/CAA Journal of Automatic Sinica</i>. 2025. (†Equal Contributors)<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/SPADE.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning</b><br>XIN Hu, Ke Qin, Guiduo Duan, <b>Ming Li</b>, Yuan-Fang Li, Tao He. <i>ICCV</i>. 2025.<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/colonnerf.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>ColonNeRF: Neural Radiance Fields for High-Fidelity Long-Sequence Colonoscopy Reconstruction</b><br>Yufei Shi, Beijia Lu, Jia-Wei Liu, <b>Ming Li</b> and Mike Zheng Shou. <i>Neurocomputing</i>. 2025.<br>
[<a href="http://arxiv.org/abs/2312.02015">Paper</a>][<a href="https://showlab.github.io/ColonNeRF/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/slam.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>DEP-SLAM: A Dynamic Environment Perception SLAM System with Large Language Models</b><br>Ying He, F. Richard Yu, Fei Ma, <b>Ming Li</b>, and Guang Zhou. <i>ICASSP</i>. 2025.<br>
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/RealEra.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Corer: Concept Residue Erasing in Text-to-Image Diffusion Models</b><br>Yufan Liu, Jinyang An, Wanqian Zhang, <b>Ming Li</b>*, Dayan Wu, Jingzi Gu, Zheng Lin and Weiping Wang. <i>ICME</i>. 2025. (*Corresponding Authors)<br> 
[<a href="https://arxiv.org/abs/2410.09140">Paper</a>][<a href="https://realerasing.github.io/RealEra/">Project</a>]
<br clear="left">
</p>



<p>
<img src="https://ming1993li.github.io/images/lv_vton.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>LV-VTON: Long-Video Virtual Try-On via Enhanced Visual Autoregressive Modeling</b><br>Lulu Tian, Hongxun Yao and <b>Ming Li</b>. <i>ICME</i>. 2025.<br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>



<p>
<img src="https://ming1993li.github.io/images/omnistyle.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>OmniStyle: Attention-Optimized Global and Local Image Stylization with Diffusion Model Inversion</b><br>Jiarong Cheng, Xihang Qiu, Qing Zhou, <b>Ming Li</b>, Chun Li, Yao Lu and Fei Richard Yu. <i>ICME</i>. 2025. <br> 
[<a href="">Paper</a>][<a href="">Project</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/SemiSupervisedDiseaseClassification.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Semi-Supervised Disease Classification based on Limited Medical Image Data</b><br>Yan Zhang, Zhaoxia Liu, Chun Li and <b>Ming Li</b>. <i>Journal of Biomedical and Health Informatics</i>. 2024.<br>
[<a href="https://ieeexplore.ieee.org/document/10381816">Paper</a>][<a href="https://github.com/wmh12138/Paper_Code/tree/master/train">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/instant3d_overview.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Instant3D: Instant Text-to-3D Generation</b><br><b>Ming Li</b>, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan and Xiangyu Xu. <i>International Journal of Computer Vision</i>. 2024.<br>
[<a href="http://arxiv.org/abs/2311.08403">Paper</a>][<a href="https://ming1993li.github.io/Instant3DProj/">Project</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/FakePoI.jpg?raw=true" alt="Figure" style="width: 200px; height: 90px;" hspace="20" align="left"/>
<b>FakePoI: A Large-scale Fake Person of Interest Video Detection Benchmark and a Strong Baseline</b><br>Lulu Tian, Hongxun Yao, and <b>Ming Li</b>. <i>IEEE TCSVT</i>. 2023.<br>
[<a href="https://ieeexplore.ieee.org/document/10107587">Paper</a>][<a href="https://github.com/cslltian/deepfake-detection">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/DR_FER.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>DR-FER: Discriminative and Robust Representation Learning for Facial Expression Recognition</b><br><b>Ming Li</b>, Huazhu Fu, Shengfeng He, Hehe Fan, Jun Liu, Jussi Keppo and Mike Zheng Shou. <i>IEEE TMM</i>. 2023.<br>
[<a href="https://ieeexplore.ieee.org/abstract/document/10375788/">Paper</a>][<a href="">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/STPrivacy.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition</b><br><b>Ming Li</b>, Xiangyu Xu, Hehe Fan, Pan Zhou, Jun Liu, Jia-Wei Liu, Jiahe Li, Jussi Keppo, Mike Zheng Shou, and Shuicheng Yan. <i>ICCV</i>. 2023.<br>
[<a href="https://arxiv.org/pdf/2301.03046v2.pdf">Paper</a>][<a href="https://github.com/ming1993li/stprivacy">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/exploit_part_tmm21.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Exploiting Multi-view Part-wise Correlation via an Efficient Transformer for Vehicle Re-Identification</b><br><b>Ming Li</b>, Jun Liu, Ce Zheng, Xinming Huang, and Ziming Zhang. <i>IEEE TMM</i>. 2021 (<b>ESI Highly Cited Paper</b>).<br>
[<a href="https://ieeexplore.ieee.org/document/9647974">Paper</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/selfsupervised_iccv21.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>Self-supervised Geometric Features Discovery with Interpretable Attention for Vehicle Re-Identification and Beyond</b><br><b>Ming Li</b>, Xinming Huang, and Ziming Zhang. <i>ICCV</i>. 2021.<br>
[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Self-Supervised_Geometric_Features_Discovery_via_Interpretable_Attention_for_Vehicle_Re-Identification_ICCV_2021_paper.pdf">Paper</a>][<a href="https://github.com/ming1993li/Self-supervised-Geometric">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/ICPR20_TreeRNN.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>TreeRNN: Topology-Preserving Deep Graph Embedding and Learning</b><br>
Yecheng Lyu, <b>Ming Li</b>, Xinming Huang, Ulkuhan Guler, Patrick Schaumont, and Ziming Zhang. <i>ICPR</i>. 2020.<br>
[<a href="https://ieeexplore.ieee.org/abstract/document/9412808">Paper</a>][<a href="https://github.com/YechengLyu/TreeRNN">Code</a>]
<br clear="left">
</p>


<p>
<img src="https://ming1993li.github.io/images/ICPR20_RNN.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>RNN Training along Locally Optimal Trajectories via Frank-Wolfe Algorithm</b><br>
Yun Yue, <b>Ming Li</b>, Venkatesh Saligramay, Ziming Zhang. <i>ICPR</i>. 2020.<br>
[<a href="https://ieeexplore.ieee.org/document/9412188">Paper</a>][<a href="https://github.com/YunYunY/FW_RNN_optimizer">Code</a>]
<br clear="left">
</p>

<p>
<img src="https://ming1993li.github.io/images/lodo_mm_20_fig.jpg?raw=true" alt="Figure" style="width: 200px; height: 120px;" hspace="20" align="left"/>
<b>LodoNet: A Deep Neural Network with 2D Keypoint Matching for 3D LiDAR Odometry Estimation</b><br>
Ce Zheng, Yecheng Lyu, <b>Ming Li</b>, Ziming Zhang. <i>ACM MM</i>. 2020.<br>
[<a href="https://dl.acm.org/doi/10.1145/3394171.3413771">Paper</a>]
<br clear="left">
</p>

<!-- ## Projects ##

<p>
<a href="http://ming1993li.github.io/publications/cscada"></a>
<b><a href="http://ming1993li.github.io/publications/cscada">CSCADA: Cycle and Semantic Consistency Adversarial Domain Adaptation for Cross-Modality Medical Image Segmentation</a></b><br>
<b>Ming Li</b>. Research project. UNC at Chapel Hill, Chapel Hill, NC. 2019.<br>
</p>

<p>
<a href="http://ming1993li.github.io/publications/urvas"></a>
<b><a href="http://ming1993li.github.io/publications/urvas">Style Transfer Based Unsupervised Retinal Vessel Segmentation Adaptation</a></b><br>
<b>Ming Li</b>. Research project. UNC at Chapel Hill, Chapel Hill, NC. 2019.<br>
</p>

<p>
<a href="http://ming1993li.github.io/publications/advrv"></a>
<b><a href="http://ming1993li.github.io/publications/advrv">Adversarial Retinal Vessel Segmentation</a></b><br>
<b>Ming Li</b>. Research project. UNC at Chapel Hill, Chapel Hill, NC. 2018.<br>
</p>

<p>
<a href="http://ming1993li.github.io/publications/ee"></a>
<b><a href="http://ming1993li.github.io/publications/ee">Other experience in Electronic Engineering</a></b><br>
<b>Ming Li</b>. Research project. Peking University & Xidian University, China. 2015.<br>
</p> -->
